{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710e5023",
   "metadata": {},
   "source": [
    "# ğŸ“™ LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129537a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c472ad",
   "metadata": {},
   "source": [
    "## ğŸ“Œ RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc4af6",
   "metadata": {},
   "source": [
    "### ğŸ« RunnablePassthrough ë€?\n",
    "\n",
    "- ì…ë ¥ì„ ì•„ë¬´ ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ë„˜ê¸°ëŠ” ë¸”ë¡ (ë°ì´í„° ì „ë‹¬ ì—­í• )\n",
    "\n",
    "- ìš©ë„ : ìë¦¬ ë§¡ê¸°ìš©, ì—°ê²°ìš©, ë””ë²„ê¹…ìš©, ê³µë°± ì²˜ë¦¬ìš©\n",
    "\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ `RunnableParallel` ê³¼ í•¨ê»˜ í™œìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfee74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f848cff",
   "metadata": {},
   "source": [
    "## ğŸ“Œ RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1d865",
   "metadata": {},
   "source": [
    "### ğŸ”ƒ RunnableParallel ë€?\n",
    "\n",
    "- ì—¬ëŸ¬ ê°œì˜ Runnableì„ ë™ì‹œì— ì‹¤í–‰í•´ì£¼ëŠ” ë¸”ë¡\n",
    "\n",
    "- í•œ ê°œì˜ ì…ë ¥ì„ ì—¬ëŸ¬ ê°œë¡œ ë°›ê³ , ê°ê°ì˜ ëŒ€í•œ ê²°ê³¼ë¬¼ì„ ì—¬ëŸ¬ ê°œì˜ ê²°ê³¼ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cdb14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2436d2",
   "metadata": {},
   "source": [
    "### âœ… ê²€ìƒ‰ê¸° ì‚¬ìš©ì—ì„œ RunnablePassthroughë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ë¡€ ì‚´í´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# ë¬¸ì„œ\n",
    "docs = [\n",
    "    \"ë¬¸ê¸°ëŠ” ë­ì²´ì¸ì´ ì¢‹ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë¯¼ê¸°ëŠ” ë­ì²´ì¸ì´ ì‹«ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë¬¸ê¸°ì˜ ì§ì—…ì€ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¯¼ê¸°ì˜ ì§ì—…ì€ gangì…ë‹ˆë‹¤.\"\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œë¥¼ ê²€ìƒ‰ê¸°ë¡œ ì‚¬ìš©\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# í…œí”Œë¦¿ ì •ì˜\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# í…œí”Œë¦¿ìœ¼ë¡œë¶€í„° ì±„íŒ… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# ë¬¸ì„œë¥¼ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# ê²€ìƒ‰ ì²´ì¸ êµ¬ì„±\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490ca9d",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c87385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë¬¸ê¸°ì˜ ì§ì—…ì€ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"ë¬¸ê¸°ì˜ ì§ì—…ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79db07b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë¯¼ê¸°ëŠ” gangì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"ë¯¼ê¸°ëŠ” ë­í•˜ëŠ” ë†ˆì´ì•¼?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8149b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì£¼ì–´ì§„ ë§¥ë½ì—ëŠ” \"RunnablePassthrough\"ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"RunnablePassthroughì€ ë¬´ì—‡ì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae19a",
   "metadata": {},
   "source": [
    "### ì •ë¦¬í•˜ê¸°\n",
    "\n",
    "â˜‘ï¸ \"context\" : retriever + format_docs ì‹¤í–‰ ê²°ê³¼\n",
    "\n",
    "â˜‘ï¸ \"question\" : ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ ë“¤ì–´ê°€ì•¼ í•¨\n",
    "\n",
    "â˜‘ï¸ RunnablePassthrough() : ì§ˆë¬¸ì„ ì•„ë¬´ ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë‹¨ê³„ì— ì „ë‹¬ ëª©ì ìš©\n",
    "\n",
    "â˜‘ï¸ RunnablePassthroughëŠ” í•„ìˆ˜ ì¸ê°€?\\\n",
    "-> \"question\" í‚¤ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìˆ˜ ì‚¬í•­ì„â•\\\n",
    "-> í•´ë‹¹ í´ë˜ìŠ¤ì¼ í•„ìš”ëŠ” ì—†ì§€ë§Œ ì´ë¥¼ ëŒ€ì‹ í•  ë¬´ì–¸ê°€ëŠ” í•„ìˆ˜ë¡œ ì¡´ì¬í•´ì•¼ë§Œ í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8401c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a9b26",
   "metadata": {},
   "source": [
    "### âœ… ê°™ì€ ì§ˆë¬¸ì— ì„œë¡œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ì ìš©í•´ì„œ RunnableParallel ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17dc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸1 ì²´ì¸ ì •ì˜\n",
    "capital_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸2 ì²´ì¸ ì •ì˜\n",
    "area_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ ì‹¤í–‰ ìš© RunnableParallel ê°ì²´ ìƒì„±\n",
    "map_chain = RunnableParallel(capital=capital_chain, area=area_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03328b2b",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d183dc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'ì„œìš¸ì…ë‹ˆë‹¤.', 'area': 'ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,210 ì œê³± í‚¬ë¡œë¯¸í„°ì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆë¬¸í•˜ê¸°\n",
    "map_chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43efe99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eec66",
   "metadata": {},
   "source": [
    "### âœ… RunnablePassthroughì™€ RunnableParallel í•¨ê»˜ ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ë¬¸ì„œ\n",
    "docs = [\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ë‹¤.\",\n",
    "    \"ëŒ€í•œë¯¼êµ­ì€ ê²¨ìš¸ì— ëˆˆì´ ì˜¤ê³  ì—¬ë¦„ì—” ì¥ë§ˆê°€ ìˆë‹¤.\",\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.\",\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# LLM & íŒŒì„œ\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# format_docs í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# ê·¸ëŒ€ë¡œ ì§ˆë¬¸í•˜ëŠ” ì²´ì¸ (Passthrough)\n",
    "chain_direct = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\"ì§ˆë¬¸: {question}\\nì •í™•íˆ ëŒ€ë‹µí•´ì¤˜.\")\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸ (ë¬¸ì„œ ê¸°ë°˜)\n",
    "chain_rag = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\\në¬¸ì„œ: {context}\\nì§ˆë¬¸: {question}\"\n",
    "    )\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ë¡œ ì‹¤í–‰ (RunnableParallel)\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"LLM ë‹¨ë… ë‹µë³€\": chain_direct,\n",
    "    \"LLM & RAG ë‹µë³€\": chain_rag\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06cf21",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1386caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LLM ë‹¨ë… ë‹µë³€]\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ëŒ€ì²´ë¡œ ì˜¨ëŒ€ëª¬ìˆœ ê¸°í›„ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë©°, ê° ê³„ì ˆì˜ ê¸°ì˜¨ê³¼ ê°•ìˆ˜ëŸ‰ì— ë”°ë¼ ë‹¤ì–‘í•œ ë‚ ì”¨ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë´„(3ì›”~5ì›”)**: ë§‘ê³  ë”°ëœ»í•œ ë‚ ì”¨ê°€ ë§ìœ¼ë©°, ê½ƒì´ ë§Œê°œí•˜ëŠ” ì‹œê¸°ì…ë‹ˆë‹¤. í‰ê·  ê¸°ì˜¨ì€ ì•½ 10ë„ì—ì„œ 20ë„ ì‚¬ì´ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë´„ì² ì—ëŠ” í™©ì‚¬ì™€ ë¯¸ì„¸ë¨¼ì§€ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì—¬ë¦„(6ì›”~8ì›”)**: ë¥ê³  ìŠµí•œ ë‚ ì”¨ê°€ íŠ¹ì§•ì´ë©°, í‰ê·  ê¸°ì˜¨ì€ 25ë„ì—ì„œ 35ë„ ì‚¬ì´ì…ë‹ˆë‹¤. ì´ ì‹œê¸°ì—ëŠ” ì¥ë§ˆê°€ ì‹œì‘ë˜ì–´ ë§ì€ ë¹„ê°€ ë‚´ë¦¬ë©°, ìŠµë„ê°€ ë†’ì•„ì ¸ ë¶ˆì¾Œì§€ìˆ˜ê°€ ì˜¬ë¼ê°‘ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê°€ì„(9ì›”~11ì›”)**: ë§‘ê³  ì„ ì„ í•œ ë‚ ì”¨ë¡œ, ë‹¨í’ì´ ì•„ë¦„ë‹µê²Œ ë¬¼ë“œëŠ” ì‹œê¸°ì…ë‹ˆë‹¤. í‰ê·  ê¸°ì˜¨ì€ ì•½ 10ë„ì—ì„œ 20ë„ ì‚¬ì´ë¡œ, ì¾Œì í•œ ë‚ ì”¨ê°€ ì§€ì†ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê²¨ìš¸(12ì›”~2ì›”)**: ì¶¥ê³  ê±´ì¡°í•œ ë‚ ì”¨ê°€ ì´ì–´ì§€ë©°, í‰ê·  ê¸°ì˜¨ì€ 0ë„ì—ì„œ -10ë„ ì‚¬ì´ì…ë‹ˆë‹¤. íŠ¹íˆ, ë¶ë¶€ì§€ì—­ì€ ëˆˆì´ ë§ì´ ì˜¤ê³ , ë‚¨ë¶€ì§€ì—­ì€ ìƒëŒ€ì ìœ¼ë¡œ ì˜¨ë‚œí•œ ê²¨ìš¸ì„ ê²½í—˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì „ë°˜ì ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì€ ì‚¬ê³„ì ˆì˜ ë³€í™”ê°€ ëšœë ·í•˜ì—¬ ê° ê³„ì ˆë§ˆë‹¤ ë‹¤ì–‘í•œ ìì—° ê²½ê´€ê³¼ ê¸°í›„ íŠ¹ì„±ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì§€ì—­ì— ë”°ë¼ ê¸°í›„ ì°¨ì´ê°€ ìˆì–´, ì„œìš¸ê³¼ ë¶€ì‚°, ì œì£¼ë„ ë“±ì—ì„œì˜ ê¸°ì˜¨ê³¼ ê°•ìˆ˜ëŸ‰ì€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[LLM & RAG ë‹µë³€]\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•©ë‹ˆë‹¤. ê²¨ìš¸ì—ëŠ” ëˆˆì´ ë‚´ë¦¬ê³ , ì—¬ë¦„ì—ëŠ” ì¥ë§ˆê°€ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•ë¶„ì— ê° ê³„ì ˆë§ˆë‹¤ ë‹¤ì–‘í•œ ë‚ ì”¨ì™€ í’ê²½ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = parallel_chain.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ê°€ ê¶ê¸ˆí•´\")\n",
    "\n",
    "print(\"\\n[LLM ë‹¨ë… ë‹µë³€]\\n\")\n",
    "print(result[\"LLM ë‹¨ë… ë‹µë³€\"])\n",
    "\n",
    "print(\"\\n[LLM & RAG ë‹µë³€]\\n\")\n",
    "print(result[\"LLM & RAG ë‹µë³€\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208486a3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7ecc7",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í† "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ecde4",
   "metadata": {},
   "source": [
    "### ğŸ“ˆ Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í† \n",
    "- Runnableì˜ íë¦„ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0a398",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -qU faiss-cpu tiktoken\n",
    "\n",
    "# ê·¸ë˜í”„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7258bf",
   "metadata": {},
   "source": [
    "### ì¼ë°˜ì ì¸ ì²´ì¸ êµ¬ì„± ìƒ˜í”Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e903c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    # í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œë¶€í„° FAISS ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    [\"TeddyëŠ” AI ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.\", \"TeddyëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì¢‹ì•„í•©ë‹ˆë‹¤!\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"ë‹¤ìŒ ë§¥ë½ë§Œì„ í† ëŒ€ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.:\n",
    "{context}  \n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "# í…œí”Œë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ ChatPromptTemplateì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39fbcb",
   "metadata": {},
   "source": [
    "### Runnableì˜ ê·¸ë˜í”„ ì–»ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10435fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9e99e544dd5f46d39b9827e4f250790b': Node(id='9e99e544dd5f46d39b9827e4f250790b', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " '1961b2b62b8d496f86fb81ffb2d0029e': Node(id='1961b2b62b8d496f86fb81ffb2d0029e', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " '2b3e089446224bdda73e584caed61770': Node(id='2b3e089446224bdda73e584caed61770', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1694c8690>, search_kwargs={}), metadata=None),\n",
       " 'dd95ff52bf2947749987f4c8ad52350e': Node(id='dd95ff52bf2947749987f4c8ad52350e', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '9f1ac3dec1f74dcd9a7a92d1dd28ffe5': Node(id='9f1ac3dec1f74dcd9a7a92d1dd28ffe5', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})]), metadata=None),\n",
       " '9b7f66f84a6f4546bbf919bcc480f5dc': Node(id='9b7f66f84a6f4546bbf919bcc480f5dc', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x168ccc150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x168db4bd0>, root_client=<openai.OpenAI object at 0x168d4b2d0>, root_async_client=<openai.AsyncOpenAI object at 0x16973e1d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " 'a1bf6c53db194cd5b4d51ac97e031929': Node(id='a1bf6c53db194cd5b4d51ac97e031929', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " 'c07c81c584434144836022291a8d11dd': Node(id='c07c81c584434144836022291a8d11dd', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ì—ì„œ ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc52cc",
   "metadata": {},
   "source": [
    "- ë…¸ë“œ(Node): ê°ê°ì˜ ì²˜ë¦¬ ë‹¨ê³„ (ì˜ˆ: retriever, prompt, model ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74379298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='c525746f8cf2494eb90f2c08097eded9', target='5e45775b2cb444c0a674d3d5004a1760', data=None, conditional=False),\n",
       " Edge(source='5e45775b2cb444c0a674d3d5004a1760', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='c525746f8cf2494eb90f2c08097eded9', target='d50f4826cfc74a28bdc8e3aaa3e31292', data=None, conditional=False),\n",
       " Edge(source='d50f4826cfc74a28bdc8e3aaa3e31292', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='863efcd269944b3486ace0c82316e1f1', target='46cae50d6a4e4934a1440d4afc4be280', data=None, conditional=False),\n",
       " Edge(source='46cae50d6a4e4934a1440d4afc4be280', target='f667874687d14d7fbe43aa9ffe4812da', data=None, conditional=False),\n",
       " Edge(source='ed2d1a69a5634b40b8f5e711d7004b53', target='6270c2309d4b4d4390a2cbc297860425', data=None, conditional=False),\n",
       " Edge(source='f667874687d14d7fbe43aa9ffe4812da', target='ed2d1a69a5634b40b8f5e711d7004b53', data=None, conditional=False)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ì—ì„œ ì—£ì§€ë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cccba",
   "metadata": {},
   "source": [
    "- ì—£ì§€(Edge): ê·¸ ì²˜ë¦¬ ë‹¨ê³„ë“¤ ì‚¬ì´ë¥¼ ì—°ê²°í•˜ëŠ” â€œí™”ì‚´í‘œâ€ë‚˜ â€œì„ â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c9a5c",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868de14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ë¥¼ ASCII í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b2601",
   "metadata": {},
   "source": [
    "### â˜‘ï¸ ì •ë¦¬í•˜ê¸°\n",
    "\n",
    "1.\tParallelInput: ì²´ì¸ì˜ ë§¨ ì•ì—ì„œ \"context\"ì™€ \"question\" ë‘ ê°œì˜ keyì— ëŒ€í•´ ë™ì‹œì— ì²˜ë¦¬ ì¤€ë¹„\n",
    "\n",
    "2.\tVectorStoreRetriever: \"context\" ê°’ ìƒì„±ì„ ìœ„í•´ retriever ì‹¤í–‰ (ë²¡í„° ê²€ìƒ‰)\n",
    "\n",
    "3.\tPassthrough: \"question\"ì€ ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ í†µê³¼\n",
    "\n",
    "4.\tParallelOutput: \"context\" + \"question\" â†’ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ê¹€\n",
    "\n",
    "5.\tChatPromptTemplate: {context}\\nQuestion: {question} í˜•íƒœì˜ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "\n",
    "6.\tChatOpenAI: í”„ë¡¬í”„íŠ¸ë¥¼ LLM(GPT-4o-mini)ì— ì „ë‹¬ â†’ ì‘ë‹µ ìƒì„±\n",
    "\n",
    "7.\tStrOutputParser: ëª¨ë¸ ì‘ë‹µì„ íŒŒì‹±í•´ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "8.\tStrOutputParserOutput: ìµœì¢… ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da67315",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d704f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6cac7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194c1e0",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ë™ì  ì†ì„± ì§€ì • (configurable_fields, configurable_alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df6317",
   "metadata": {},
   "source": [
    "### â›“ï¸â€ğŸ’¥ ëŸ°íƒ€ì„ì— ì²´ì¸ ë‚´ë¶€ êµ¬ì„±í•˜ê¸°\n",
    "\n",
    "- `configurable_fields` ì‹œìŠ¤í…œì˜ ì„¤ì • ê°’ì„ ì •ì˜í•˜ëŠ” í•„ë“œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `configurable_alternatives` ëŸ°íƒ€ì„ì— ì„¤ì •í•  ìˆ˜ ìˆëŠ” Runnable ëŒ€ì•ˆì„ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa78b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681551f3",
   "metadata": {},
   "source": [
    "### configurable_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a6b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default=ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})]) fields={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "print(prompt.configurable_fields())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3dfbf",
   "metadata": {},
   "source": [
    "-> configurable_fieldsì˜ ì˜í•´ì„œ í•´ë‹¹ í…œí”Œë¦¿ì€ êµì²´ ê°€ëŠ¥í•œ í•„ë“œë¡œ ì§€ì •ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a556d",
   "metadata": {},
   "source": [
    "### ì–¸ì œ ì“°ì´ëŠ”ê°€ â‰ï¸\n",
    "\n",
    "- ëŸ°íƒ€ì„ì— í”„ë¡¬í”„íŠ¸ë¥¼ êµì²´í•˜ëŠ” ê²½ìš°\n",
    "\n",
    "- ë™ì ìœ¼ë¡œ ëª¨ë¸ì„ ë³€ê²½í•˜ê±°ë‚˜, íŒŒë¼ë¯¸í„° ê°’ì„ ì‹¤í—˜í•˜ëŠ” ê²½ìš°\n",
    "\n",
    "- ì„¤ì • ê°’ì„ .with_config() ë“±ìœ¼ë¡œ ë°”ê¿€ ê²½ìš°\n",
    "\n",
    "- ì„œë²„, UI ë“±ì—ì„œ ì™¸ë¶€ ì„¤ì • ì£¼ì…í•´ì•¼í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294aa2c",
   "metadata": {},
   "source": [
    "### ëŸ°íƒ€ì„ì— í”„ë¡¬í”„íŠ¸ë¥¼ êµì²´í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a39d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "# ê¸°ë³¸ ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | ChatOpenAI()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ë¥¼ êµì²´í•˜ê³  ì‹¶ë‹¤ë©´?\n",
    "new_prompt = ChatPromptTemplate.from_template(\"Explain {topic} to a 5-year-old\")\n",
    "chain = chain.with_config(configurable={\"prompt\": new_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0490bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default=RunnableBinding(bound=ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})])\n",
      "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12215d550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x120c5a150>, root_client=<openai.OpenAI object at 0x121287210>, root_async_client=<openai.AsyncOpenAI object at 0x1224c7d90>, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={}, config={'configurable': {'prompt': ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} to a 5-year-old'), additional_kwargs={})])}}, config_factories=[]) fields={}\n"
     ]
    }
   ],
   "source": [
    "print(chain.configurable_fields())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e53ef6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541cbe6",
   "metadata": {},
   "source": [
    "### ë™ì ìœ¼ë¡œ ëª¨ë¸ì„ ë³€ê²½í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdcd74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 8,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 23,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_a288987b44',\n",
       "  'id': 'chatcmpl-Bp6z13FM6gROnpOXHaNnflloxxKIt',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-bff8624b-0038-4fa1-93da-5fd01f367787-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 8,\n",
       "  'total_tokens': 23,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "model.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b595e",
   "metadata": {},
   "source": [
    "`configurable_fields` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `model_name` ì†ì„±ì„ ë™ì  êµ¬ì„± ê°€ëŠ¥í•œ í•„ë“œë¡œ ì§€ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868c7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).configurable_fields(\n",
    "    model_name=ConfigurableField(  # model_name ì€ ì›ë˜ ChatOpenAI ì˜ í•„ë“œì…ë‹ˆë‹¤.\n",
    "        id=\"gpt_version\",  # model_name ì˜ id ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        name=\"Version of GPT\",  # model_name ì˜ ì´ë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a8250",
   "metadata": {},
   "source": [
    "`model.invoke()` í˜¸ì¶œì‹œ `config={\"configurable\": {\"í‚¤\": \"ê°’\"}}` í˜•ì‹ìœ¼ë¡œ ë™ì  ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4780eb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 16,\n",
       "   'prompt_tokens': 22,\n",
       "   'total_tokens': 38,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-Bp7ztHPzsqMM7XDZSXRJderAhtTz7',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-4f664bb5-2f59-4d5e-ab58-dbd682f7729f-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 22,\n",
       "  'output_tokens': 16,\n",
       "  'total_tokens': 38,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\",\n",
    "    # gpt_version ì„ gpt-3.5-turbo ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-3.5-turbo\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cfdcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 8,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 23,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_34a54ae93c',\n",
       "  'id': 'chatcmpl-Bp74KPMOKmYd5dmx5ySfMnRLKoBa4',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-d7bb556f-53d2-4705-a62e-a03716affe25-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 8,\n",
       "  'total_tokens': 23,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    # gpt_version ì„ gpt-4o-mini ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\",\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-4o-mini\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cacbd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243248fc",
   "metadata": {},
   "source": [
    "### ì„¤ì •ê°’ì„ .with_config() ë°”ê¿€ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126664ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Why did the banana go to the doctor? \\n\\nBecause it wasn't peeling very well! ğŸŒ\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 13, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BpP1kfGNEVptGeXMzIcEDgdM8jNJv', 'finish_reason': 'stop', 'logprobs': None} id='run--e395786e-c94c-4163-a073-e9122c44f5bf-0' usage_metadata={'input_tokens': 13, 'output_tokens': 19, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì›ë˜ ì²´ì¸\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "chain = prompt | llm\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì¹œì ˆí•˜ê²Œ ë°”ê¾¸ê³  ì‹¶ì„ ë•Œ\n",
    "new_prompt = ChatPromptTemplate.from_template(\"Can you kindly tell a joke about {topic}?\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ë§Œ êµì²´\n",
    "reconfigured_chain = chain.with_config(configurable={\"prompt\": new_prompt})\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(reconfigured_chain.invoke({\"topic\": \"bananas\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763bfa26",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3be917",
   "metadata": {},
   "source": [
    "### Configuable Alternatives: Runnable ê°ì²´ ìì²´ì˜ ëŒ€ì•ˆ ì„¤ì •\n",
    "\n",
    "- `ChatAnthropic` ì˜ êµ¬ì„± ê°€ëŠ¥í•œ ì–¸ì–´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì‘ì—…ê³¼ ì»¨í…ìŠ¤íŠ¸ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "- ë™ì ìœ¼ë¡œ ì„¤ì •(Config) ê°’ì„ ë³€ê²½í•˜ê¸° ìœ„í•˜ì—¬ ëª¨ë¸ì— ì„¤ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ConfigurableField ê°ì²´ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0de27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    temperature=0, model=\"claude-3-5-sonnet-20240620\"\n",
    ").configurable_alternatives(\n",
    "\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "\n",
    "    default_key=\"anthropic\",\n",
    "\n",
    "    openai=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    gpt4o=ChatOpenAI(model=\"gpt-4o\"),\n",
    "\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropicì„ ê¸°ë³¸ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "chain.invoke({\"topic\": \"ë‰´ì§„ìŠ¤\"}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a731e9",
   "metadata": {},
   "source": [
    "{'content': 'ë‰´ì§„ìŠ¤(NewJeans)ëŠ” 2022ë…„ 7ì›” 22ì¼ì— ë°ë·”í•œ ëŒ€í•œë¯¼êµ­ì˜ 5ì¸ì¡° ê±¸ê·¸ë£¹ì…ë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. ì†Œì†ì‚¬: ADOR (HYBE Labelsì˜ ìíšŒì‚¬)\\n\\n2. ë©¤ë²„: ë¯¼ì§€, í•˜ë‹ˆ, ë‹¤ë‹ˆì—˜, í•´ë¦°, í˜œì¸\\n\\n3. ë°ë·”ê³¡: \"Attention\", \"Hype Boy\", \"Cookie\"\\n\\n4. íŠ¹ì§•:\\n   - 10ëŒ€ ë©¤ë²„ë“¤ë¡œ êµ¬ì„±ëœ ì‹ ì„ í•œ ì´ë¯¸ì§€\\n   - Y2K, 90ë…„ëŒ€ ê°ì„±ì„ í˜„ëŒ€ì ìœ¼ë¡œ ì¬í•´ì„í•œ ìŒì•…ê³¼ ìŠ¤íƒ€ì¼\\n   - ë…íŠ¹í•œ ë§ˆì¼€íŒ… ì „ëµ (ì‚¬ì „ í™ë³´ ì—†ì´ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë°ë·”)\\n\\n5. ì£¼ìš” ì„±ê³¼:\\n   - ë°ë·” ì•¨ë²” \\'ë‰´ ì§„ìŠ¤(New Jeans)\\'ë¡œ ë¹Œë³´ë“œ 200 ì°¨íŠ¸ ì§„ì…\\n   - ì—¬ëŸ¬ ìŒì› ì°¨íŠ¸ 1ìœ„ ê¸°ë¡\\n   - ê°ì¢… ì‹ ì¸ìƒ ìˆ˜ìƒ\\n\\në‰´ì§„ìŠ¤ëŠ” ë°ë·” ì´í›„ ë¹ ë¥´ê²Œ ì¸ê¸°ë¥¼ ì–»ìœ¼ë©° 4ì„¸ëŒ€ K-popì„ ëŒ€í‘œí•˜ëŠ” ê·¸ë£¹ìœ¼ë¡œ ìë¦¬ë§¤ê¹€í•˜ê³  ìˆìŠµë‹ˆë‹¤.', 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_01PJfWdBpgp2FbWp1t3HfQP4',  'model': 'claude-3-5-sonnet-20240620',  'stop_reason': 'end_turn',  'stop_sequence': None,  'usage': {'input_tokens': 30, 'output_tokens': 390}}, 'type': 'ai', 'name': None, 'id': 'run-68b3570d-a0d4-4074-9d69-cbf40b3caf8b-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 30,  'output_tokens': 390,  'total_tokens': 420}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b67217",
   "metadata": {},
   "source": [
    "-> ChatAnthropic ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•˜ì—¬ API KEYë¥¼ ë°œê¸‰ë°›ì•„ ì„¤ì •í•´ì•¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4f650",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d780f74",
   "metadata": {},
   "source": [
    "## ğŸ“Œ RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1f04d",
   "metadata": {},
   "source": [
    "### ğŸ“ RunnableWithMessageHistoryë€?\n",
    "\n",
    "- RunnableWithMessageHistoryëŠ” LangChain ì²´ì¸ì— â€œì±„íŒ… ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬â€ë¥¼ ì—°ê²°í•´ì£¼ëŠ” ë˜í¼\n",
    "\n",
    "- ì‚¬ìš©ìì˜ ëŒ€í™”ë¥¼ ê³„ì† ê¸°ì–µí•˜ë©´ì„œ â€œëŒ€í™”í˜• ì±—ë´‡â€ì²˜ëŸ¼ ë™ì‘í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a067a1",
   "metadata": {},
   "source": [
    "### ì‹¤ì œ í™œìš© ì˜ˆì‹œ\n",
    "\n",
    "- ëŒ€í™”í˜• ì±—ë´‡ ê°œë°œ: ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë‚´ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ì±—ë´‡ì˜ ì‘ë‹µì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ë³µì¡í•œ ë°ì´í„° ì²˜ë¦¬: ë°ì´í„° ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì˜ ë¡œì§ì„ ê²°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ìƒíƒœ ê´€ë¦¬ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜: ì‚¬ìš©ìì˜ ì´ì „ ì„ íƒì„ ê¸°ì–µí•˜ê³  ê·¸ì— ë”°ë¼ ë‹¤ìŒ í™”ë©´ì´ë‚˜ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4e652",
   "metadata": {},
   "source": [
    "### íœ˜ë°œì„± ëŒ€í™”ê¸°ë¡: ì¸ë©”ëª¨ë¦¬(In-Memory)\n",
    "\n",
    "ì‚¬ìš©ìì™€ ì£¼ê³ ë°›ì€ ë©”ì‹œì§€ë¥¼ ë©”ëª¨ë¦¬ì—ë§Œ ì ê¹ ì €ì¥í•˜ê³ ,\n",
    "\n",
    "í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ë©´ ê¸°ì–µì´ ì‚¬ë¼ì§€ëŠ” êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "308cf388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[human] ì•ˆë…•?\n",
      "[ai] ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°ì²´ ìƒì„± (íœ˜ë°œì„±)\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# ì‚¬ìš©ì â†’ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì €ì¥\n",
    "history.add_user_message(\"ì•ˆë…•?\")\n",
    "history.add_ai_message(\"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\")\n",
    "\n",
    "# ì¶œë ¥í•´ë³´ê¸°\n",
    "for msg in history.messages:\n",
    "    print(f\"[{msg.type}] {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c0d61",
   "metadata": {},
   "source": [
    "### íœ˜ë°œì„± ì‹¤ì‚¬ìš© ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e499bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# ì²´ì¸\n",
    "chain = prompt | ChatOpenAI(model_name=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "# ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ\n",
    "store = {}\n",
    "\n",
    "# get_session_history í•¨ìˆ˜ ìˆ˜ì •\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ë¶™ì¸ ì²´ì¸ êµ¬ì„±\n",
    "chat_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d460a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\n",
      "ì–´ë–¤ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ë„ì‹œì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ê·¸ ì§€ì—­ì˜ ë‚ ì”¨ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user-1234\"\n",
    "\n",
    "print(chat_chain.invoke(\n",
    "    {\"input\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    "))\n",
    "\n",
    "print(chat_chain.invoke(\n",
    "    {\"input\": \"ê·¸ ë„ì‹œì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198541d",
   "metadata": {},
   "source": [
    "-> ì¶œë ¥ë§ˆë‹¤ InMemoryì— ì˜í•´ ëŒ€í™” ê¸°ë¡ì´ íœ˜ë°œë˜ì–´ ê·¸ ë„ì‹œë¼ê³  ì§ˆë¬¸í•˜ê²Œ ë˜ë©´ ì¶œë ¥í•˜ì§€ ëª»í•˜ê²Œ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de6207",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71bf276",
   "metadata": {},
   "source": [
    "### âœ… ë©”ì‹œì§€ ê¸°ë¡(ë©”ëª¨ë¦¬) ì¶”ê°€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f4734",
   "metadata": {},
   "source": [
    "### ğŸ›‘ RedisChatMessageHistory\n",
    "\n",
    "- Redisë¥¼ í†µí•œ ëŒ€í™” ê¸°ë¡ ì˜êµ¬ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91ed9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Redis ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜\n",
    "def get_history(session_id: str):\n",
    "    return RedisChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        url=\"redis://223.130.143.231:6379\",  # ğŸ”§ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ì¡°ì • (cloudì´ë©´ URLë¡œ)\n",
    "        ttl=None  # Noneì´ë©´ ë¬´ì œí•œ ì €ì¥\n",
    "    )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ êµ¬ì„± â€” ë°˜ë“œì‹œ {history} í¬í•¨!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"placeholder\", \"{history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# ì²´ì¸ ì •ì˜\n",
    "base_chain = prompt | ChatOpenAI(model_name=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì ìš©\n",
    "chat_chain = RunnableWithMessageHistory(\n",
    "    base_chain,\n",
    "    get_session_history=get_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a6b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\n",
      "í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì—, êµ¬ì²´ì ì¸ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦´ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ë©°, ì—¬ë¦„ì€ ë¥ê³  ìŠµí•˜ë©°, ê²¨ìš¸ì€ ì¶¥ê³  ê±´ì¡°í•©ë‹ˆë‹¤. ê°€ì„ê³¼ ë´„ì€ ë¹„êµì  ì˜¨í™”í•œ ë‚ ì”¨ë¥¼ ë³´ì…ë‹ˆë‹¤. ì •í™•í•œ ë‚ ì”¨ ì •ë³´ë¥¼ ì•Œê³  ì‹¶ë‹¤ë©´ ë‚ ì”¨ ì˜ˆë³´ ì›¹ì‚¬ì´íŠ¸ë‚˜ ëª¨ë°”ì¼ ì•±ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user-5678\"  # ê³ ì •ëœ ì‚¬ìš©ì ID\n",
    "\n",
    "# 1. ì²« ë²ˆì§¸ ì§ˆë¬¸\n",
    "print(chat_chain.invoke(\n",
    "    {\"input\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    "))\n",
    "\n",
    "# 2. ì´ì–´ì§€ëŠ” ë¬¸ë§¥ ì§ˆë¬¸ (ë‹¤ì‹œ ì‹¤í–‰í•´ë„ Redisê°€ ê¸°ì–µ)\n",
    "print(chat_chain.invoke(\n",
    "    {\"input\": \"ê·¸ ë„ì‹œì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235ed9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdde38e",
   "metadata": {},
   "source": [
    "### ğŸ›‘ RunnableWithMessageHistory\n",
    "\n",
    "- ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³ , ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ë©°, ë” ì •êµí•œ ì‘ë‹µ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea5ac16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runnable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     13\u001b[39m         store[session_ids] = ChatMessageHistory()\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m store[session_ids]  \u001b[38;5;66;03m# í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜\u001b[39;00m\n\u001b[32m     17\u001b[39m with_message_history = (\n\u001b[32m     18\u001b[39m     RunnableWithMessageHistory(  \u001b[38;5;66;03m# RunnableWithMessageHistory ê°ì²´ ìƒì„±\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[43mrunnable\u001b[49m,  \u001b[38;5;66;03m# ì‹¤í–‰í•  Runnable ê°ì²´\u001b[39;00m\n\u001b[32m     20\u001b[39m         get_session_history,  \u001b[38;5;66;03m# ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\u001b[39;00m\n\u001b[32m     21\u001b[39m         input_messages_key=\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤\u001b[39;00m\n\u001b[32m     22\u001b[39m         history_messages_key=\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\u001b[39;00m\n\u001b[32m     23\u001b[39m     )\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'runnable' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "\n",
    "# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°\n",
    "        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜\n",
    "\n",
    "\n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory ê°ì²´ ìƒì„±\n",
    "        runnable,  # ì‹¤í–‰í•  Runnable ê°ì²´\n",
    "        get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "        input_messages_key=\"input\",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤\n",
    "        history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcfd199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ëƒ¥ RunnableWithMessageHistoryë§Œ ì“°ê¸°\n",
    "chat_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=lambda session_id: ...,  # history return\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "701838cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'Ratio of the adjacent side length to the hypotenuse length in a right triangle.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 17,\n",
       "   'prompt_tokens': 160,\n",
       "   'total_tokens': 177,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-BpBmf29kO2x9yMy6ItNq3ClkztIeC',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-9e34f702-7d71-4a5a-b960-aa7aa57af9d7-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 160,\n",
       "  'output_tokens': 17,\n",
       "  'total_tokens': 177,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ \"ì½”ì‚¬ì¸ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    # ì„¤ì • ì •ë³´ë¡œ ì„¸ì…˜ ID \"abc123\"ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5025bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'ì§ê° ì‚¼ê°í˜•ì—ì„œ ì¸ì ‘í•œ ë³€ì˜ ê¸¸ì´ë¥¼ ë¹—ë³€ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆˆ ë¹„ìœ¨ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 41,\n",
       "   'prompt_tokens': 202,\n",
       "   'total_tokens': 243,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'id': 'chatcmpl-BpBmmVi7wssMOWjPhIrVOFDthCK2e',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-bb95f1e5-d58b-4196-a5e5-008b11f03342-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 202,\n",
       "  'output_tokens': 41,\n",
       "  'total_tokens': 243,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë©”ì‹œì§€ ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "with_message_history.invoke(\n",
    "    # ëŠ¥ë ¥ê³¼ ì…ë ¥ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    {\"ability\": \"math\", \"input\": \"ì´ì „ì˜ ë‚´ìš©ì„ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"},\n",
    "    # ì„¤ì • ì˜µì…˜ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096d44d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ì¶”ê°€ ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6bbbf",
   "metadata": {},
   "source": [
    "### ëŒ€í™” íˆìŠ¤í† ë¦¬ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9f0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™” íˆìŠ¤í† ë¦¬\n",
      "\n",
      "ì‚¬ìš©ì: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\n",
      "\n",
      "GPT: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì: ê·¸ ë„ì‹œì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\n",
      "\n",
      "GPT: í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì—, êµ¬ì²´ì ì¸ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•´ ë“œë¦´ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ë©°, ì—¬ë¦„ì€ ë¥ê³  ìŠµí•˜ë©°, ê²¨ìš¸ì€ ì¶¥ê³  ê±´ì¡°í•©ë‹ˆë‹¤. ê°€ì„ê³¼ ë´„ì€ ë¹„êµì  ì˜¨í™”í•œ ë‚ ì”¨ë¥¼ ë³´ì…ë‹ˆë‹¤. ì •í™•í•œ ë‚ ì”¨ ì •ë³´ë¥¼ ì•Œê³  ì‹¶ë‹¤ë©´ ë‚ ì”¨ ì˜ˆë³´ ì›¹ì‚¬ì´íŠ¸ë‚˜ ëª¨ë°”ì¼ ì•±ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import redis, json\n",
    "\n",
    "r = redis.Redis(host=\"223.130.143.231\", port=6379, decode_responses=True)\n",
    "# Redisì— ì €ì¥ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ í‚¤\n",
    "key = \"message_store:user-5678\"\n",
    "\n",
    "# Redisì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "messages = r.lrange(key, 0, -1)\n",
    "\n",
    "# í•„ìš”í•œ í•„ë“œ ì¶œë ¥ì‹œí‚¤ê¸°\n",
    "print(\"ëŒ€í™” íˆìŠ¤í† ë¦¬\\n\")\n",
    "for raw in reversed(messages):\n",
    "    msg = json.loads(raw)\n",
    "    role = msg[\"type\"]\n",
    "    content = msg[\"data\"][\"content\"]\n",
    "    role = \"ì‚¬ìš©ì\" if role == \"human\" else \"GPT\"\n",
    "    print(f\"{role}: {content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa520de",
   "metadata": {},
   "source": [
    "### ìœ„ì˜ íˆìŠ¤í† ë¦¬ ë‚´ìš©ì„ FAISS ì €ì¥ì†Œì— ì €ì¥í•œ í›„ ê²€ìƒ‰ê¸°ë¡œ AI ë‹µë³€ êµ¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ë²¡í„°í™”(ì„ë² ë”©)ëœ ë¬¸ì„œë“¤ì„ ê°€ì ¸ì™€ì„œ FAISS ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±\n",
    "docs = [json.loads(m)[\"data\"][\"content\"] for m in messages]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# ë²¡í„°ì €ì¥ì†Œë¥¼ ê²€ìƒ‰ê¸°ë¡œ ì‚¬ìš©\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807fd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# AIê°€ ë‹µë³€í•  í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œ:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "# ì „ì²´ RAG ì²´ì¸ êµ¬ì„±\n",
    "rag_chain = (\n",
    "    # ë”•ì…”ë„ˆë¦¬ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëŒë‹¤ í•¨ìˆ˜\n",
    "    {\"context\": lambda x: retriever.invoke(x[\"question\"]), \"question\": lambda x: x[\"question\"]}\n",
    "    | prompt\n",
    "    | ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1359ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•©ë‹ˆë‹¤. ì—¬ë¦„ì€ ë¥ê³  ìŠµí•˜ë©°, ê²¨ìš¸ì€ ì¶¥ê³  ê±´ì¡°í•©ë‹ˆë‹¤. ê°€ì„ê³¼ ë´„ì€ ë¹„êµì  ì˜¨í™”í•œ ë‚ ì”¨ë¥¼ ë³´ì…ë‹ˆë‹¤. ì •í™•í•œ ë‚ ì”¨ ì •ë³´ë¥¼ ì›í•˜ì‹ ë‹¤ë©´ ë‚ ì”¨ ì˜ˆë³´ ì›¹ì‚¬ì´íŠ¸ë‚˜ ëª¨ë°”ì¼ ì•±ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì‹¤í–‰\n",
    "print(rag_chain.invoke({\"question\": \"ê·¸ ë„ì‹œì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c8b7d",
   "metadata": {},
   "source": [
    "### -> Redisì— ì‚¬ìš©ì ê³ ì • ì„¸ì…˜ê°’ì•ˆì—ì„œ ììœ ë¡­ê²Œ AIì™€ ëŒ€í™”í•˜ê³ , í•´ë‹¹ ì„¸ì…˜ê°’ì— ì €ì¥ëœ ëŒ€í™” ë‚´ìš©ë“¤ì„ ë°”ë¡œ ë°”ë¡œ FAISSë‚˜ Chroma ì €ì¥ì†Œì— ì„ë² ë”© ì‹œì¼œ ì €ì¥í•˜ë©´, ë‚˜ë§Œì˜ ì±—ë´‡ì„ êµ¬í˜„í•´ ë³¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf38d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f72e3f",
   "metadata": {},
   "source": [
    "## @chain ë°ì½”ë ˆì´í„°ë€\n",
    "\n",
    "- ìš°ì„  Pythonì˜ ë°ì½”ë ˆì´í„°ë€? í•¨ìˆ˜ë‚˜ ë©”ì„œë“œì˜ ê¸°ëŠ¥ì„ í™•ì¥í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a837c0c",
   "metadata": {},
   "source": [
    "### ì¼ë°˜ì ì¸ í•¨ìˆ˜ í˜¸ì¶œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb29219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ ì‹¤í–‰ ì „...\n",
      "ì•ˆë…•í•˜ì„¸ìš”\n",
      "í•¨ìˆ˜ ì‹¤í–‰ í›„!!\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\"í•¨ìˆ˜ ì‹¤í–‰ ì „...\")\n",
    "        func()\n",
    "        print(\"í•¨ìˆ˜ ì‹¤í–‰ í›„!!\")\n",
    "    return wrapper\n",
    "\n",
    "def hello():\n",
    "    print(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "\n",
    "decorated_hello = my_decorator(hello)\n",
    "decorated_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025b5a2",
   "metadata": {},
   "source": [
    "### @ë°ì½”ë ˆì´í„° í˜•ì‹ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f074cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ ì‹¤í–‰ ì „...\n",
      "ì•ˆë…•í•˜ì„¸ìš”\n",
      "í•¨ìˆ˜ ì‹¤í–‰ í›„!!\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\"í•¨ìˆ˜ ì‹¤í–‰ ì „...\")\n",
    "        func()\n",
    "        print(\"í•¨ìˆ˜ ì‹¤í–‰ í›„!!\")\n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def say_hello():\n",
    "    print(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "\n",
    "say_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fc60e",
   "metadata": {},
   "source": [
    "- my_decorator í•¨ìˆ˜ëŠ” say_hello í•¨ìˆ˜ë¥¼ ê°ì‹¸ê³  ìˆëŠ” í˜•íƒœë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- `@my_decorator` ëŠ” say_hello = my_decorator(say_hello)ì™€ ë™ì¼í•œ í‘œí˜„ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31e0685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ í˜¸ì¶œ ì „...\n",
      "ê³„ì‚° ì¤‘: 3 + 5\n",
      "í•¨ìˆ˜ í˜¸ì¶œ í›„!!\n",
      "ê²°ê³¼: 8\n"
     ]
    }
   ],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"í•¨ìˆ˜ í˜¸ì¶œ ì „...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(\"í•¨ìˆ˜ í˜¸ì¶œ í›„!!\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def add(a, b):\n",
    "    print(f\"ê³„ì‚° ì¤‘: {a} + {b}\")\n",
    "    return a + b\n",
    "\n",
    "result = add(3, 5)\n",
    "print(\"ê²°ê³¼:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abbc9e",
   "metadata": {},
   "source": [
    "1. @my_decoratorë¥¼ ë³´ê³ , addë¥¼ my_decorator(add)ë¡œ ì¹˜í™˜í•œë‹¤.\n",
    "\n",
    "2. my_decoratorí•¨ìˆ˜ëŠ” ë‚´ë¶€ wrapperí•¨ìˆ˜ë¥¼ ìˆ˜í–‰í•˜ê³  wrapperë¥¼ ë°˜í™˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fac09",
   "metadata": {},
   "source": [
    "### @chain ë°ì½”ë ˆì´í„°ë€?\n",
    "\n",
    "- í•¨ìˆ˜ë¥¼ í•˜ë‚˜ì˜ Runnable ì²´ì¸ìœ¼ë¡œ ìë™ ë³€í™˜í•´ì£¼ëŠ” ë°ì½”ë ˆì´í„°\n",
    "\n",
    "-> ì‰½ê²Œ ë§í•´ì„œ @chainì„ í•¨ìˆ˜ ìœ„ì— ë¶™ì´ë©´, ê·¸ í•¨ìˆ˜ëŠ” ìë™ìœ¼ë¡œ ì²´ì¸ì²˜ëŸ¼ .invoke() .stream() .batch()ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc8b71",
   "metadata": {},
   "source": [
    "| ê°„ë‹¨í•œ ê¸°ë³¸ ì‚¬ìš©ë²• ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c954d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def weather_chain(input: str) -> str:\n",
    "    return f\"ì˜¤ëŠ˜ì˜ {input} ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924978e4",
   "metadata": {},
   "source": [
    "- ì´ì œ weather_chainì€ LangChainì˜ Runnableì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "722d707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ì˜ ë¶€ì‚° ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "print(weather_chain.invoke(\"ë¶€ì‚°\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c85e725",
   "metadata": {},
   "source": [
    "|  LLMê³¼ í•¨ê»˜ ì‚¬ìš©ë  ê²½ìš° ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "321f4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "@chain\n",
    "def city_chain(input: str) -> str:\n",
    "    prompt = ChatPromptTemplate.from_template(\"{input}ì˜ ë„ì‹œëŠ” ì–´ë–¤ê±° ê°™ì•„?\")\n",
    "    return prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aea126",
   "metadata": {},
   "source": [
    "- ë§ˆì°¬ê°€ì§€ë¡œ city_chainí•¨ìˆ˜ëŠ” @chainë°ì½”ë ˆì´í„° ì²˜ë¦¬ë˜ì–´ Runnableì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d162fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶€ì‚°ì€ í•œêµ­ì—ì„œ ë‘ ë²ˆì§¸ë¡œ í° ë„ì‹œë¡œ, ì•„ë¦„ë‹¤ìš´ í•´ë³€ê³¼ ë…íŠ¹í•œ ë¬¸í™”, ë§›ìˆëŠ” ìŒì‹ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. í•´ìš´ëŒ€, ê´‘ì•ˆë¦¬ì™€ ê°™ì€ í•´ë³€ì€ íŠ¹íˆ ì—¬ë¦„ì² ì— ë§ì€ ê´€ê´‘ê°ë“¤ì´ ì°¾ëŠ” ì¸ê¸° ëª…ì†Œì…ë‹ˆë‹¤. ë˜í•œ, ë¶€ì‚° êµ­ì œì˜í™”ì œì™€ ê°™ì€ ë‹¤ì–‘í•œ ë¬¸í™” í–‰ì‚¬ë„ ì—´ë¦¬ë©°, ì´ê³³ì˜ í™œê¸°ì°¬ ë¶„ìœ„ê¸°ë¥¼ ë”í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ë¶€ì‚°ì€ ë˜í•œ í•­êµ¬ ë„ì‹œë¡œ, êµ­ì œì ì¸ ë¬´ì—­ê³¼ ë¬¼ë¥˜ì˜ ì¤‘ì‹¬ì§€ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ë¬¸í™”ê°€ ì–´ìš°ëŸ¬ì§€ëŠ” ë…íŠ¹í•œ ë§¤ë ¥ì„ ì§€ë‹ˆê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì§€ì—­ íŠ¹ì‚°ë¬¼ì¸ ë°€ë©´, ì”¨ì•—í˜¸ë–¡, ìƒì„ íšŒ ë“±ì€ ìŒì‹ìœ¼ë¡œë„ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë¶€ì‚°ì€ ìì—°ê²½ê´€ë„ ë›°ì–´ë‚˜í•´ ë™ë°±ì„¬, íƒœì¢…ëŒ€, ê¸ˆì •ì‚° ë“±ì˜ ê´€ê´‘ëª…ì†Œê°€ ìˆì–´ ë‹¤ì–‘í•œ ì•¼ì™¸ í™œë™ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ë“¯ ë¶€ì‚°ì€ í˜„ëŒ€ì ì¸ ë„ì‹œì˜ ë§¤ë ¥ê³¼ ìì—°ì˜ ì•„ë¦„ë‹¤ì›€ì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” íŠ¹ë³„í•œ ê³³ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(city_chain.invoke(\"ë¶€ì‚°\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca442f",
   "metadata": {},
   "source": [
    "### @chain ë°ì½”ë ˆì´í„°ëŠ” ì–¸ì œ í˜¹ì€ ì–´ë””ì— ì“°ì´ëŠ” ê°€?\n",
    "\n",
    "- .invoke() .stream() ë“± Runnable í”„ë¡œí† ì½œ ìë™ ì ìš©ë˜ì–´ ì¥ì ì´ ìˆë‹¤.\n",
    "\n",
    "- ë³µì¡í•œ ì²´ì¸ì„ ì§ì ‘ | íŒŒì´í”„ë¡œ ì—°ê²°í•˜ì§€ ì•Šê³  í•¨ìˆ˜ë¡œ ì •ì˜í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "- ì²´ì¸ì„ í•¨ìˆ˜ì²˜ëŸ¼ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab5efc",
   "metadata": {},
   "source": [
    "| êµì¬ì— ë‚´ìš©ëŒ€ë¡œ @chain ë°ì½”ë ˆì´í„°ë¡œ Runnable ê°ì²´ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfdfe8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f43c5",
   "metadata": {},
   "source": [
    "- prompt1 ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•œ ì§§ì€ ì„¤ëª… í”„ë¡¬í”„íŠ¸\n",
    "- prompt2 ì˜ì–´ë¡œ ë²ˆì—­í•´ë‹¬ë¼ëŠ” ìš”ì²­ í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88fa91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ì§§ê²Œ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} ë¥¼ emojië¥¼ í™œìš©í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œê¸€ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86112556",
   "metadata": {},
   "source": [
    "- custom_chain í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ë°ì½”ë ˆì´í„°ë¡œ Runnableí•œ ê°ì²´ë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12b0ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    chain1 = prompt1 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    chain2 = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    return chain2.invoke({\"sentence\": output1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40c948",
   "metadata": {},
   "source": [
    "- custom_chain í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3446bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¾âœ¨ ì–‘ìì—­í•™: ë¯¸ì„¸í•œ ì„¸ê³„ì˜ ë¹„ë°€ ğŸ”¬âš›ï¸\n",
      "\n",
      "ì–‘ìì—­í•™ì€ ğŸ¦  ì•„ì›ì ì…ìì™€ ê°™ì€ ì‘ì€ ìŠ¤ì¼€ì¼ì˜ ë™ì‘ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤! ğŸ” ê³ ì „ ë¬¼ë¦¬í•™ìœ¼ë¡œëŠ” ì´í•´í•  ìˆ˜ ì—†ëŠ” ì‹ ë¹„ë¡œìš´ í˜„ìƒë“¤ì„ ë‹¤ë¤˜ì£ . \n",
      "\n",
      "ì£¼ìš” ê°œë…ìœ¼ë¡œëŠ”:\n",
      "ğŸŒŠ íŒŒë™-ì…ì ì´ì¤‘ì„±\n",
      "ğŸ”’ ë¶ˆí™•ì‹¤ì„± ì›ë¦¬\n",
      "ğŸ”— ì–‘ì ì–½í˜\n",
      "\n",
      "ì–‘ìì—­í•™ì€ ë¬¼ì§ˆì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ìƒí˜¸ì‘ìš©ì„ ì´í•´í•˜ëŠ” ë° í•„ìˆ˜ì ì´ë©°, ğŸš€ ë°˜ë„ì²´, ğŸŒŸ ë ˆì´ì €, â˜¢ï¸ ì›ìë ¥ ë“± í˜„ëŒ€ ê¸°ìˆ ì˜ ê¸°ì´ˆë¥¼ ë‹¤ì§€ê³  ìˆì–´ìš”! ğŸ’¡\n",
      "\n",
      "#ì–‘ìì—­í•™ #ë¬¼ë¦¬í•™ #ê³¼í•™ #íŒŒë™ì…ìì´ì¤‘ì„± #ë¶ˆí™•ì •ì„±ì›ë¦¬ #ì–‘ìì–½í˜ #í˜„ëŒ€ê¸°ìˆ  #ê³µë¶€í•˜ëŠ”ì¦ê±°ì›€\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"ì–‘ìì—­í•™\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-langchain-uZ1tu061-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
