{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710e5023",
   "metadata": {},
   "source": [
    "# 📙 LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129537a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c472ad",
   "metadata": {},
   "source": [
    "## 📌 RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc4af6",
   "metadata": {},
   "source": [
    "### 🎫 RunnablePassthrough 란?\n",
    "\n",
    "- 입력을 아무 변경 없이 그대로 넘기는 블록 (데이터 전달 역할)\n",
    "\n",
    "- 용도 : 자리 맡기용, 연결용, 디버깅용, 공백 처리용\n",
    "\n",
    "- 일반적으로 `RunnableParallel` 과 함께 활용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfee74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f848cff",
   "metadata": {},
   "source": [
    "## 📌 RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1d865",
   "metadata": {},
   "source": [
    "### 🔃 RunnableParallel 란?\n",
    "\n",
    "- 여러 개의 Runnable을 동시에 실행해주는 블록\n",
    "\n",
    "- 한 개의 입력을 여러 개로 받고, 각각의 대한 결과물을 여러 개의 결과로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cdb14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2436d2",
   "metadata": {},
   "source": [
    "### ✅ 검색기 사용에서 RunnablePassthrough를 사용하는 사례 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 문서\n",
    "docs = [\n",
    "    \"문기는 랭체인이 좋습니다.\",\n",
    "    \"민기는 랭체인이 싫습니다.\",\n",
    "    \"문기의 직업은 엔지니어입니다.\",\n",
    "    \"민기의 직업은 gang입니다.\"\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 벡터 저장소를 검색기로 사용\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 템플릿 정의\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# 템플릿으로부터 채팅 프롬프트를 생성합니다.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 문서를 포맷팅하는 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 검색 체인 구성\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490ca9d",
   "metadata": {},
   "source": [
    "### 실행 및 결과 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c87385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문기의 직업은 엔지니어입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"문기의 직업은 무엇입니까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79db07b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'민기는 gang입니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"민기는 뭐하는 놈이야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8149b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 맥락에는 \"RunnablePassthrough\"에 대한 정보가 포함되어 있지 않습니다. 따라서 답변할 수 없습니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"RunnablePassthrough은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae19a",
   "metadata": {},
   "source": [
    "### 정리하기\n",
    "\n",
    "☑️ \"context\" : retriever + format_docs 실행 결과\n",
    "\n",
    "☑️ \"question\" : 입력값 그대로 들어가야 함\n",
    "\n",
    "☑️ RunnablePassthrough() : 질문을 아무 수정 없이 그대로 다음 단계에 전달 목적용\n",
    "\n",
    "☑️ RunnablePassthrough는 필수 인가?\\\n",
    "-> \"question\" 키를 처리하기 위해 필수 사항임❕\\\n",
    "-> 해당 클래스일 필요는 없지만 이를 대신할 무언가는 필수로 존재해야만 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8401c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a9b26",
   "metadata": {},
   "source": [
    "### ✅ 같은 질문에 서로 다른 프롬프트를 병렬로 적용해서 RunnableParallel 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17dc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 프롬프트1 체인 정의\n",
    "capital_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} 의 수도는 어디입니까?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 프롬프트2 체인 정의\n",
    "area_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} 의 면적은 얼마입니까?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 병렬 실행 용 RunnableParallel 객체 생성\n",
    "map_chain = RunnableParallel(capital=capital_chain, area=area_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03328b2b",
   "metadata": {},
   "source": [
    "### 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d183dc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': '서울입니다.', 'area': '대한민국의 면적은 약 100,210 제곱 킬로미터입니다.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문하기\n",
    "map_chain.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43efe99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eec66",
   "metadata": {},
   "source": [
    "### ✅ RunnablePassthrough와 RunnableParallel 함께 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 문서\n",
    "docs = [\n",
    "    \"대한민국의 기후는 사계절이 뚜렷하다.\",\n",
    "    \"대한민국은 겨울에 눈이 오고 여름엔 장마가 있다.\",\n",
    "    \"대한민국의 수도는 서울이다.\",\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# LLM & 파서\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# format_docs 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# 그대로 질문하는 체인 (Passthrough)\n",
    "chain_direct = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\"질문: {question}\\n정확히 대답해줘.\")\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# RAG 체인 (문서 기반)\n",
    "chain_rag = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"다음 문서를 참고하여 질문에 답하세요.\\n문서: {context}\\n질문: {question}\"\n",
    "    )\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# 병렬로 실행 (RunnableParallel)\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"LLM 단독 답변\": chain_direct,\n",
    "    \"LLM & RAG 답변\": chain_rag\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06cf21",
   "metadata": {},
   "source": [
    "### 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1386caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LLM 단독 답변]\n",
      "\n",
      "대한민국의 기후는 대체로 온대몬순 기후로 분류됩니다. 사계절이 뚜렷하게 나타나는 것이 특징이며, 각 계절의 기온과 강수량에 따라 다양한 날씨 패턴을 보입니다.\n",
      "\n",
      "1. **봄(3월~5월)**: 맑고 따뜻한 날씨가 많으며, 꽃이 만개하는 시기입니다. 평균 기온은 약 10도에서 20도 사이입니다. 그러나 봄철에는 황사와 미세먼지가 발생할 수 있습니다.\n",
      "\n",
      "2. **여름(6월~8월)**: 덥고 습한 날씨가 특징이며, 평균 기온은 25도에서 35도 사이입니다. 이 시기에는 장마가 시작되어 많은 비가 내리며, 습도가 높아져 불쾌지수가 올라갑니다.\n",
      "\n",
      "3. **가을(9월~11월)**: 맑고 선선한 날씨로, 단풍이 아름답게 물드는 시기입니다. 평균 기온은 약 10도에서 20도 사이로, 쾌적한 날씨가 지속됩니다.\n",
      "\n",
      "4. **겨울(12월~2월)**: 춥고 건조한 날씨가 이어지며, 평균 기온은 0도에서 -10도 사이입니다. 특히, 북부지역은 눈이 많이 오고, 남부지역은 상대적으로 온난한 겨울을 경험합니다.\n",
      "\n",
      "전반적으로 대한민국은 사계절의 변화가 뚜렷하여 각 계절마다 다양한 자연 경관과 기후 특성을 즐길 수 있습니다. 또한, 지역에 따라 기후 차이가 있어, 서울과 부산, 제주도 등에서의 기온과 강수량은 다르게 나타날 수 있습니다.\n",
      "\n",
      "[LLM & RAG 답변]\n",
      "\n",
      "대한민국의 기후는 사계절이 뚜렷합니다. 겨울에는 눈이 내리고, 여름에는 장마가 있습니다. 이러한 특징 덕분에 각 계절마다 다양한 날씨와 풍경을 경험할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "result = parallel_chain.invoke(\"대한민국의 기후가 궁금해\")\n",
    "\n",
    "print(\"\\n[LLM 단독 답변]\\n\")\n",
    "print(result[\"LLM 단독 답변\"])\n",
    "\n",
    "print(\"\\n[LLM & RAG 답변]\\n\")\n",
    "print(result[\"LLM & RAG 답변\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208486a3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7ecc7",
   "metadata": {},
   "source": [
    "## 📌 Runnable 구조(그래프) 검토"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ecde4",
   "metadata": {},
   "source": [
    "### 📈 Runnable 구조(그래프) 검토\n",
    "- Runnable의 흐름을 이해하기 위한 그래프 그려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0a398",
   "metadata": {},
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 설치\n",
    "!pip install -qU faiss-cpu tiktoken\n",
    "\n",
    "# 그래프 라이브러리 설치\n",
    "!pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7258bf",
   "metadata": {},
   "source": [
    "### 일반적인 체인 구성 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e903c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    # 텍스트 데이터로부터 FAISS 벡터 저장소를 생성합니다.\n",
    "    [\"Teddy는 AI 엔지니어입니다.\", \"Teddy는 프로그래밍을 좋아합니다!\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# 벡터 저장소를 기반으로 retriever를 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"다음 맥락만을 토대로 질문에 답하세요.:\n",
    "{context}  \n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "# 템플릿을 기반으로 ChatPromptTemplate을 생성합니다.\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다.\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39fbcb",
   "metadata": {},
   "source": [
    "### Runnable의 그래프 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10435fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9e99e544dd5f46d39b9827e4f250790b': Node(id='9e99e544dd5f46d39b9827e4f250790b', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " '1961b2b62b8d496f86fb81ffb2d0029e': Node(id='1961b2b62b8d496f86fb81ffb2d0029e', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " '2b3e089446224bdda73e584caed61770': Node(id='2b3e089446224bdda73e584caed61770', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1694c8690>, search_kwargs={}), metadata=None),\n",
       " 'dd95ff52bf2947749987f4c8ad52350e': Node(id='dd95ff52bf2947749987f4c8ad52350e', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '9f1ac3dec1f74dcd9a7a92d1dd28ffe5': Node(id='9f1ac3dec1f74dcd9a7a92d1dd28ffe5', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})]), metadata=None),\n",
       " '9b7f66f84a6f4546bbf919bcc480f5dc': Node(id='9b7f66f84a6f4546bbf919bcc480f5dc', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x168ccc150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x168db4bd0>, root_client=<openai.OpenAI object at 0x168d4b2d0>, root_async_client=<openai.AsyncOpenAI object at 0x16973e1d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " 'a1bf6c53db194cd5b4d51ac97e031929': Node(id='a1bf6c53db194cd5b4d51ac97e031929', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " 'c07c81c584434144836022291a8d11dd': Node(id='c07c81c584434144836022291a8d11dd', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 노드 가져오기\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc52cc",
   "metadata": {},
   "source": [
    "- 노드(Node): 각각의 처리 단계 (예: retriever, prompt, model 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74379298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='c525746f8cf2494eb90f2c08097eded9', target='5e45775b2cb444c0a674d3d5004a1760', data=None, conditional=False),\n",
       " Edge(source='5e45775b2cb444c0a674d3d5004a1760', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='c525746f8cf2494eb90f2c08097eded9', target='d50f4826cfc74a28bdc8e3aaa3e31292', data=None, conditional=False),\n",
       " Edge(source='d50f4826cfc74a28bdc8e3aaa3e31292', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='863efcd269944b3486ace0c82316e1f1', target='46cae50d6a4e4934a1440d4afc4be280', data=None, conditional=False),\n",
       " Edge(source='46cae50d6a4e4934a1440d4afc4be280', target='f667874687d14d7fbe43aa9ffe4812da', data=None, conditional=False),\n",
       " Edge(source='ed2d1a69a5634b40b8f5e711d7004b53', target='6270c2309d4b4d4390a2cbc297860425', data=None, conditional=False),\n",
       " Edge(source='f667874687d14d7fbe43aa9ffe4812da', target='ed2d1a69a5634b40b8f5e711d7004b53', data=None, conditional=False)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 엣지를 가져오기\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cccba",
   "metadata": {},
   "source": [
    "- 엣지(Edge): 그 처리 단계들 사이를 연결하는 “화살표”나 “선”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c9a5c",
   "metadata": {},
   "source": [
    "### 그래프 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868de14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "# 체인의 그래프를 ASCII 형식으로 출력\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b2601",
   "metadata": {},
   "source": [
    "### ☑️ 정리하기\n",
    "\n",
    "1.\tParallelInput: 체인의 맨 앞에서 \"context\"와 \"question\" 두 개의 key에 대해 동시에 처리 준비\n",
    "\n",
    "2.\tVectorStoreRetriever: \"context\" 값 생성을 위해 retriever 실행 (벡터 검색)\n",
    "\n",
    "3.\tPassthrough: \"question\"은 입력값 그대로 통과\n",
    "\n",
    "4.\tParallelOutput: \"context\" + \"question\" → 딕셔너리로 묶어서 다음 단계로 넘김\n",
    "\n",
    "5.\tChatPromptTemplate: {context}\\nQuestion: {question} 형태의 프롬프트 생성\n",
    "\n",
    "6.\tChatOpenAI: 프롬프트를 LLM(GPT-4o-mini)에 전달 → 응답 생성\n",
    "\n",
    "7.\tStrOutputParser: 모델 응답을 파싱해서 문자열로 변환\n",
    "\n",
    "8.\tStrOutputParserOutput: 최종 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-langchain-uZ1tu061-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
