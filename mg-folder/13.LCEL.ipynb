{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710e5023",
   "metadata": {},
   "source": [
    "# ğŸ“™ LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129537a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c472ad",
   "metadata": {},
   "source": [
    "## ğŸ“Œ RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc4af6",
   "metadata": {},
   "source": [
    "### ğŸ« RunnablePassthrough ë€?\n",
    "\n",
    "- ì…ë ¥ì„ ì•„ë¬´ ë³€ê²½ ì—†ì´ ê·¸ëŒ€ë¡œ ë„˜ê¸°ëŠ” ë¸”ë¡ (ë°ì´í„° ì „ë‹¬ ì—­í• )\n",
    "\n",
    "- ìš©ë„ : ìë¦¬ ë§¡ê¸°ìš©, ì—°ê²°ìš©, ë””ë²„ê¹…ìš©, ê³µë°± ì²˜ë¦¬ìš©\n",
    "\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ `RunnableParallel` ê³¼ í•¨ê»˜ í™œìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfee74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f848cff",
   "metadata": {},
   "source": [
    "## ğŸ“Œ RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1d865",
   "metadata": {},
   "source": [
    "### ğŸ”ƒ RunnableParallel ë€?\n",
    "\n",
    "- ì—¬ëŸ¬ ê°œì˜ Runnableì„ ë™ì‹œì— ì‹¤í–‰í•´ì£¼ëŠ” ë¸”ë¡\n",
    "\n",
    "- í•œ ê°œì˜ ì…ë ¥ì„ ì—¬ëŸ¬ ê°œë¡œ ë°›ê³ , ê°ê°ì˜ ëŒ€í•œ ê²°ê³¼ë¬¼ì„ ì—¬ëŸ¬ ê°œì˜ ê²°ê³¼ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cdb14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2436d2",
   "metadata": {},
   "source": [
    "### âœ… ê²€ìƒ‰ê¸° ì‚¬ìš©ì—ì„œ RunnablePassthroughë¥¼ ì‚¬ìš©í•˜ëŠ” ì‚¬ë¡€ ì‚´í´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# ë¬¸ì„œ\n",
    "docs = [\n",
    "    \"ë¬¸ê¸°ëŠ” ë­ì²´ì¸ì´ ì¢‹ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë¯¼ê¸°ëŠ” ë­ì²´ì¸ì´ ì‹«ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë¬¸ê¸°ì˜ ì§ì—…ì€ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¯¼ê¸°ì˜ ì§ì—…ì€ gangì…ë‹ˆë‹¤.\"\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œë¥¼ ê²€ìƒ‰ê¸°ë¡œ ì‚¬ìš©\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# í…œí”Œë¦¿ ì •ì˜\n",
    "template = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# í…œí”Œë¦¿ìœ¼ë¡œë¶€í„° ì±„íŒ… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# ë¬¸ì„œë¥¼ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# ê²€ìƒ‰ ì²´ì¸ êµ¬ì„±\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490ca9d",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c87385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë¬¸ê¸°ì˜ ì§ì—…ì€ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"ë¬¸ê¸°ì˜ ì§ì—…ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79db07b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë¯¼ê¸°ëŠ” gangì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"ë¯¼ê¸°ëŠ” ë­í•˜ëŠ” ë†ˆì´ì•¼?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8149b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì£¼ì–´ì§„ ë§¥ë½ì—ëŠ” \"RunnablePassthrough\"ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"RunnablePassthroughì€ ë¬´ì—‡ì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae19a",
   "metadata": {},
   "source": [
    "### ì •ë¦¬í•˜ê¸°\n",
    "\n",
    "â˜‘ï¸ \"context\" : retriever + format_docs ì‹¤í–‰ ê²°ê³¼\n",
    "\n",
    "â˜‘ï¸ \"question\" : ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ ë“¤ì–´ê°€ì•¼ í•¨\n",
    "\n",
    "â˜‘ï¸ RunnablePassthrough() : ì§ˆë¬¸ì„ ì•„ë¬´ ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë‹¨ê³„ì— ì „ë‹¬ ëª©ì ìš©\n",
    "\n",
    "â˜‘ï¸ RunnablePassthroughëŠ” í•„ìˆ˜ ì¸ê°€?\\\n",
    "-> \"question\" í‚¤ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìˆ˜ ì‚¬í•­ì„â•\\\n",
    "-> í•´ë‹¹ í´ë˜ìŠ¤ì¼ í•„ìš”ëŠ” ì—†ì§€ë§Œ ì´ë¥¼ ëŒ€ì‹ í•  ë¬´ì–¸ê°€ëŠ” í•„ìˆ˜ë¡œ ì¡´ì¬í•´ì•¼ë§Œ í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8401c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a9b26",
   "metadata": {},
   "source": [
    "### âœ… ê°™ì€ ì§ˆë¬¸ì— ì„œë¡œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ì ìš©í•´ì„œ RunnableParallel ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17dc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸1 ì²´ì¸ ì •ì˜\n",
    "capital_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸2 ì²´ì¸ ì •ì˜\n",
    "area_chain = (\n",
    "    ChatPromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì…ë‹ˆê¹Œ?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ ì‹¤í–‰ ìš© RunnableParallel ê°ì²´ ìƒì„±\n",
    "map_chain = RunnableParallel(capital=capital_chain, area=area_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03328b2b",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d183dc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'ì„œìš¸ì…ë‹ˆë‹¤.', 'area': 'ëŒ€í•œë¯¼êµ­ì˜ ë©´ì ì€ ì•½ 100,210 ì œê³± í‚¬ë¡œë¯¸í„°ì…ë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆë¬¸í•˜ê¸°\n",
    "map_chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43efe99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eec66",
   "metadata": {},
   "source": [
    "### âœ… RunnablePassthroughì™€ RunnableParallel í•¨ê»˜ ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# ë¬¸ì„œ\n",
    "docs = [\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ë‹¤.\",\n",
    "    \"ëŒ€í•œë¯¼êµ­ì€ ê²¨ìš¸ì— ëˆˆì´ ì˜¤ê³  ì—¬ë¦„ì—” ì¥ë§ˆê°€ ìˆë‹¤.\",\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.\",\n",
    "]\n",
    "vectorstore = FAISS.from_texts(docs, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# LLM & íŒŒì„œ\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# format_docs í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# ê·¸ëŒ€ë¡œ ì§ˆë¬¸í•˜ëŠ” ì²´ì¸ (Passthrough)\n",
    "chain_direct = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\"ì§ˆë¬¸: {question}\\nì •í™•íˆ ëŒ€ë‹µí•´ì¤˜.\")\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸ (ë¬¸ì„œ ê¸°ë°˜)\n",
    "chain_rag = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\\në¬¸ì„œ: {context}\\nì§ˆë¬¸: {question}\"\n",
    "    )\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# ë³‘ë ¬ë¡œ ì‹¤í–‰ (RunnableParallel)\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"LLM ë‹¨ë… ë‹µë³€\": chain_direct,\n",
    "    \"LLM & RAG ë‹µë³€\": chain_rag\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06cf21",
   "metadata": {},
   "source": [
    "### ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1386caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LLM ë‹¨ë… ë‹µë³€]\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ëŒ€ì²´ë¡œ ì˜¨ëŒ€ëª¬ìˆœ ê¸°í›„ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ì‚¬ê³„ì ˆì´ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë©°, ê° ê³„ì ˆì˜ ê¸°ì˜¨ê³¼ ê°•ìˆ˜ëŸ‰ì— ë”°ë¼ ë‹¤ì–‘í•œ ë‚ ì”¨ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë´„(3ì›”~5ì›”)**: ë§‘ê³  ë”°ëœ»í•œ ë‚ ì”¨ê°€ ë§ìœ¼ë©°, ê½ƒì´ ë§Œê°œí•˜ëŠ” ì‹œê¸°ì…ë‹ˆë‹¤. í‰ê·  ê¸°ì˜¨ì€ ì•½ 10ë„ì—ì„œ 20ë„ ì‚¬ì´ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë´„ì² ì—ëŠ” í™©ì‚¬ì™€ ë¯¸ì„¸ë¨¼ì§€ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì—¬ë¦„(6ì›”~8ì›”)**: ë¥ê³  ìŠµí•œ ë‚ ì”¨ê°€ íŠ¹ì§•ì´ë©°, í‰ê·  ê¸°ì˜¨ì€ 25ë„ì—ì„œ 35ë„ ì‚¬ì´ì…ë‹ˆë‹¤. ì´ ì‹œê¸°ì—ëŠ” ì¥ë§ˆê°€ ì‹œì‘ë˜ì–´ ë§ì€ ë¹„ê°€ ë‚´ë¦¬ë©°, ìŠµë„ê°€ ë†’ì•„ì ¸ ë¶ˆì¾Œì§€ìˆ˜ê°€ ì˜¬ë¼ê°‘ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê°€ì„(9ì›”~11ì›”)**: ë§‘ê³  ì„ ì„ í•œ ë‚ ì”¨ë¡œ, ë‹¨í’ì´ ì•„ë¦„ë‹µê²Œ ë¬¼ë“œëŠ” ì‹œê¸°ì…ë‹ˆë‹¤. í‰ê·  ê¸°ì˜¨ì€ ì•½ 10ë„ì—ì„œ 20ë„ ì‚¬ì´ë¡œ, ì¾Œì í•œ ë‚ ì”¨ê°€ ì§€ì†ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê²¨ìš¸(12ì›”~2ì›”)**: ì¶¥ê³  ê±´ì¡°í•œ ë‚ ì”¨ê°€ ì´ì–´ì§€ë©°, í‰ê·  ê¸°ì˜¨ì€ 0ë„ì—ì„œ -10ë„ ì‚¬ì´ì…ë‹ˆë‹¤. íŠ¹íˆ, ë¶ë¶€ì§€ì—­ì€ ëˆˆì´ ë§ì´ ì˜¤ê³ , ë‚¨ë¶€ì§€ì—­ì€ ìƒëŒ€ì ìœ¼ë¡œ ì˜¨ë‚œí•œ ê²¨ìš¸ì„ ê²½í—˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì „ë°˜ì ìœ¼ë¡œ ëŒ€í•œë¯¼êµ­ì€ ì‚¬ê³„ì ˆì˜ ë³€í™”ê°€ ëšœë ·í•˜ì—¬ ê° ê³„ì ˆë§ˆë‹¤ ë‹¤ì–‘í•œ ìì—° ê²½ê´€ê³¼ ê¸°í›„ íŠ¹ì„±ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì§€ì—­ì— ë”°ë¼ ê¸°í›„ ì°¨ì´ê°€ ìˆì–´, ì„œìš¸ê³¼ ë¶€ì‚°, ì œì£¼ë„ ë“±ì—ì„œì˜ ê¸°ì˜¨ê³¼ ê°•ìˆ˜ëŸ‰ì€ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[LLM & RAG ë‹µë³€]\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ëŠ” ì‚¬ê³„ì ˆì´ ëšœë ·í•©ë‹ˆë‹¤. ê²¨ìš¸ì—ëŠ” ëˆˆì´ ë‚´ë¦¬ê³ , ì—¬ë¦„ì—ëŠ” ì¥ë§ˆê°€ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•ë¶„ì— ê° ê³„ì ˆë§ˆë‹¤ ë‹¤ì–‘í•œ ë‚ ì”¨ì™€ í’ê²½ì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = parallel_chain.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ê¸°í›„ê°€ ê¶ê¸ˆí•´\")\n",
    "\n",
    "print(\"\\n[LLM ë‹¨ë… ë‹µë³€]\\n\")\n",
    "print(result[\"LLM ë‹¨ë… ë‹µë³€\"])\n",
    "\n",
    "print(\"\\n[LLM & RAG ë‹µë³€]\\n\")\n",
    "print(result[\"LLM & RAG ë‹µë³€\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208486a3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7ecc7",
   "metadata": {},
   "source": [
    "## ğŸ“Œ Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í† "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ecde4",
   "metadata": {},
   "source": [
    "### ğŸ“ˆ Runnable êµ¬ì¡°(ê·¸ë˜í”„) ê²€í† \n",
    "- Runnableì˜ íë¦„ì„ ì´í•´í•˜ê¸° ìœ„í•œ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0a398",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -qU faiss-cpu tiktoken\n",
    "\n",
    "# ê·¸ë˜í”„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7258bf",
   "metadata": {},
   "source": [
    "### ì¼ë°˜ì ì¸ ì²´ì¸ êµ¬ì„± ìƒ˜í”Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e903c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    # í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œë¶€í„° FAISS ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    [\"TeddyëŠ” AI ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.\", \"TeddyëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì¢‹ì•„í•©ë‹ˆë‹¤!\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"ë‹¤ìŒ ë§¥ë½ë§Œì„ í† ëŒ€ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.:\n",
    "{context}  \n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "# í…œí”Œë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ ChatPromptTemplateì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39fbcb",
   "metadata": {},
   "source": [
    "### Runnableì˜ ê·¸ë˜í”„ ì–»ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10435fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9e99e544dd5f46d39b9827e4f250790b': Node(id='9e99e544dd5f46d39b9827e4f250790b', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " '1961b2b62b8d496f86fb81ffb2d0029e': Node(id='1961b2b62b8d496f86fb81ffb2d0029e', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " '2b3e089446224bdda73e584caed61770': Node(id='2b3e089446224bdda73e584caed61770', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1694c8690>, search_kwargs={}), metadata=None),\n",
       " 'dd95ff52bf2947749987f4c8ad52350e': Node(id='dd95ff52bf2947749987f4c8ad52350e', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '9f1ac3dec1f74dcd9a7a92d1dd28ffe5': Node(id='9f1ac3dec1f74dcd9a7a92d1dd28ffe5', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}  \\n\\nQuestion: {question}'), additional_kwargs={})]), metadata=None),\n",
       " '9b7f66f84a6f4546bbf919bcc480f5dc': Node(id='9b7f66f84a6f4546bbf919bcc480f5dc', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x168ccc150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x168db4bd0>, root_client=<openai.OpenAI object at 0x168d4b2d0>, root_async_client=<openai.AsyncOpenAI object at 0x16973e1d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " 'a1bf6c53db194cd5b4d51ac97e031929': Node(id='a1bf6c53db194cd5b4d51ac97e031929', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " 'c07c81c584434144836022291a8d11dd': Node(id='c07c81c584434144836022291a8d11dd', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ì—ì„œ ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc52cc",
   "metadata": {},
   "source": [
    "- ë…¸ë“œ(Node): ê°ê°ì˜ ì²˜ë¦¬ ë‹¨ê³„ (ì˜ˆ: retriever, prompt, model ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74379298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='c525746f8cf2494eb90f2c08097eded9', target='5e45775b2cb444c0a674d3d5004a1760', data=None, conditional=False),\n",
       " Edge(source='5e45775b2cb444c0a674d3d5004a1760', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='c525746f8cf2494eb90f2c08097eded9', target='d50f4826cfc74a28bdc8e3aaa3e31292', data=None, conditional=False),\n",
       " Edge(source='d50f4826cfc74a28bdc8e3aaa3e31292', target='863efcd269944b3486ace0c82316e1f1', data=None, conditional=False),\n",
       " Edge(source='863efcd269944b3486ace0c82316e1f1', target='46cae50d6a4e4934a1440d4afc4be280', data=None, conditional=False),\n",
       " Edge(source='46cae50d6a4e4934a1440d4afc4be280', target='f667874687d14d7fbe43aa9ffe4812da', data=None, conditional=False),\n",
       " Edge(source='ed2d1a69a5634b40b8f5e711d7004b53', target='6270c2309d4b4d4390a2cbc297860425', data=None, conditional=False),\n",
       " Edge(source='f667874687d14d7fbe43aa9ffe4812da', target='ed2d1a69a5634b40b8f5e711d7004b53', data=None, conditional=False)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ì—ì„œ ì—£ì§€ë¥¼ ê°€ì ¸ì˜¤ê¸°\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cccba",
   "metadata": {},
   "source": [
    "- ì—£ì§€(Edge): ê·¸ ì²˜ë¦¬ ë‹¨ê³„ë“¤ ì‚¬ì´ë¥¼ ì—°ê²°í•˜ëŠ” â€œí™”ì‚´í‘œâ€ë‚˜ â€œì„ â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c9a5c",
   "metadata": {},
   "source": [
    "### ê·¸ë˜í”„ ì¶œë ¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868de14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì˜ ê·¸ë˜í”„ë¥¼ ASCII í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b2601",
   "metadata": {},
   "source": [
    "### â˜‘ï¸ ì •ë¦¬í•˜ê¸°\n",
    "\n",
    "1.\tParallelInput: ì²´ì¸ì˜ ë§¨ ì•ì—ì„œ \"context\"ì™€ \"question\" ë‘ ê°œì˜ keyì— ëŒ€í•´ ë™ì‹œì— ì²˜ë¦¬ ì¤€ë¹„\n",
    "\n",
    "2.\tVectorStoreRetriever: \"context\" ê°’ ìƒì„±ì„ ìœ„í•´ retriever ì‹¤í–‰ (ë²¡í„° ê²€ìƒ‰)\n",
    "\n",
    "3.\tPassthrough: \"question\"ì€ ì…ë ¥ê°’ ê·¸ëŒ€ë¡œ í†µê³¼\n",
    "\n",
    "4.\tParallelOutput: \"context\" + \"question\" â†’ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ê¹€\n",
    "\n",
    "5.\tChatPromptTemplate: {context}\\nQuestion: {question} í˜•íƒœì˜ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "\n",
    "6.\tChatOpenAI: í”„ë¡¬í”„íŠ¸ë¥¼ LLM(GPT-4o-mini)ì— ì „ë‹¬ â†’ ì‘ë‹µ ìƒì„±\n",
    "\n",
    "7.\tStrOutputParser: ëª¨ë¸ ì‘ë‹µì„ íŒŒì‹±í•´ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "8.\tStrOutputParserOutput: ìµœì¢… ì¶œë ¥\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-langchain-uZ1tu061-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
